
Topic models have been used extensively as a
tool for corpus exploration, and a cottage in-
dustry has developed to tweak topic models
to better encode human intuitions or to better
model data. However, creating such extensions
requires expertise in machine learning unavail-
able to potential end-users of topic modeling
software. In this work, we develop a frame-
work for allowing users to iteratively refine
the topics discovered by models such as la-
tent Dirichlet alocation (LDA) by adding con-
straints that enforce that sets of words must ap-
pear together in the same topic. We incorporate
these constraints interactively by selectively
removing elements in the state of a Markov
Chain used for inference; we investigate a va-
riety of methods for incorporating this infor-
mation and demonstrate that these interactively
added constraints improve topic usefulness for
simulated and actual user sessions.
1 