
Various semantic relatedness, similarity, and distance measures have been
proposed in the past decade and many NLP-applications strongly rely on
these semantic measures. Researchers compete for better algorithms and
normally only few percentage points seem to suffice in order to prove a
new measure outperforms an older one. In this paper we present a meta-
study comparing various semantic measures and their correlation with
human judgments. We show that the results are rather inconsistent and
ask for detailed analyses as well as clarification. We argue that the defini-
tion of a shared task might bring us considerably closer to understanding
the concept of semantic relatedness.
59
60 Cramer
1 