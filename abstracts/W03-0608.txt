
We study the problem of learning to recognise
objects in the context of autonomous agents.
We cast object recognition as the process of
attaching meaningful concepts to specific re-
gions of an image. In other words, given a
set of images and their captions, the goal is to
segment the image, in either an intelligent or
naive fashion, then to find the proper mapping
between words and regions. In this paper, we
demonstrate that a model that learns spatial re-
lationships between individual words not only
provides accurate annotations, but also allows
one to perform recognition that respects the
real-time constraints of an autonomous, mobile
robot.
1 